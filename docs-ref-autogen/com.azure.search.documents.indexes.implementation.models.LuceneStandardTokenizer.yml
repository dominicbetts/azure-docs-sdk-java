### YamlMime:JavaType
uid: com.azure.search.documents.indexes.implementation.models.LuceneStandardTokenizer
fullName: com.azure.search.documents.indexes.implementation.models.LuceneStandardTokenizer
name: LuceneStandardTokenizer
nameWithType: LuceneStandardTokenizer
summary: The LuceneStandardTokenizer model.
inheritances:
- <xref href="java.lang.Object" data-throw-if-not-resolved="False" />
- <xref href="com.azure.search.documents.indexes.implementation.models.LexicalTokenizer" data-throw-if-not-resolved="False" />
inheritedMembers:
- com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.getName()
- com.azure.search.documents.indexes.implementation.models.LexicalTokenizer.validate()
- java.lang.Object.clone()
- java.lang.Object.equals(java.lang.Object)
- java.lang.Object.finalize()
- java.lang.Object.getClass()
- java.lang.Object.hashCode()
- java.lang.Object.notify()
- java.lang.Object.notifyAll()
- java.lang.Object.toString()
- java.lang.Object.wait()
- java.lang.Object.wait(long)
- java.lang.Object.wait(long,int)
syntax: public class LuceneStandardTokenizer extends LexicalTokenizer
constructors:
- com.azure.search.documents.indexes.implementation.models.LuceneStandardTokenizer.LuceneStandardTokenizer(java.lang.String)
methods:
- com.azure.search.documents.indexes.implementation.models.LuceneStandardTokenizer.getMaxTokenLength()
- com.azure.search.documents.indexes.implementation.models.LuceneStandardTokenizer.setMaxTokenLength(java.lang.Integer)
- com.azure.search.documents.indexes.implementation.models.LuceneStandardTokenizer.validate()
type: class
metadata: {}
package: com.azure.search.documents.indexes.implementation.models
artifact: com.azure:azure-search-documents:11.0.0
