### YamlMime:JavaMember
uid: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.uploadWithResponse*
fullName: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.uploadWithResponse
name: uploadWithResponse
nameWithType: EncryptedBlobAsyncClient.uploadWithResponse
members:
- uid: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.uploadWithResponse(com.azure.storage.blob.options.BlobParallelUploadOptions)
  fullName: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.uploadWithResponse(BlobParallelUploadOptions options)
  name: uploadWithResponse(BlobParallelUploadOptions options)
  nameWithType: EncryptedBlobAsyncClient.uploadWithResponse(BlobParallelUploadOptions options)
  summary: "Creates a new block blob, or updates the content of an existing block blob. Updating an existing block blob\n overwrites any existing metadata on the blob. Partial updates are not supported with this method; the content of\n the existing blob is overwritten with the new content. To perform a partial update of a block blob's, use <xref uid=\"BlockBlobAsyncClient#stageBlock(String, Flux, long)\" data-throw-if-not-resolved=\"false\">stageBlock</xref> and\n <xref uid=\"BlockBlobAsyncClient#commitBlockList(List)\" data-throw-if-not-resolved=\"false\">BlockBlobAsyncClient#commitBlockList(List)</xref>, which this method uses internally. For more information,\n see the <a href=\"https://docs.microsoft.com/rest/api/storageservices/put-block\">Azure\n Docs for Put Block</a> and the <a href=\"https://docs.microsoft.com/rest/api/storageservices/put-block-list\">Azure\n Docs for Put Block List</a>.\n <p>\n The data passed need not support multiple subscriptions/be replayable as is required in other upload methods when\n retries are enabled, and the length of the data need not be known in advance. Therefore, this method should\n support uploading any arbitrary data source, including network streams. This behavior is possible because this\n method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while\n this method may offer additional convenience, it will not be as performant as other options, which should be\n preferred when possible.\n <p>\n Typically, the greater the number of buffers used, the greater the possible parallelism when transferring the\n data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The\n trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs\n for a given scenario.\n\n <p><strong>Code Samples</strong></p>\n\n <pre>\n BlobHttpHeaders headers = new BlobHttpHeaders&#40;&#41;\n     .setContentMd5&#40;&quot;data&quot;.getBytes&#40;StandardCharsets.UTF_8&#41;&#41;\n     .setContentLanguage&#40;&quot;en-US&quot;&#41;\n     .setContentType&#40;&quot;binary&quot;&#41;;\n \n Map&lt;String, String&gt; metadata = new HashMap&lt;&gt;&#40;Collections.singletonMap&#40;&quot;metadata&quot;, &quot;value&quot;&#41;&#41;;\n Map&lt;String, String&gt; tags = new HashMap&lt;&gt;&#40;Collections.singletonMap&#40;&quot;tag&quot;, &quot;value&quot;&#41;&#41;;\n BlobRequestConditions requestConditions = new BlobRequestConditions&#40;&#41;\n     .setLeaseId&#40;leaseId&#41;\n     .setIfUnmodifiedSince&#40;OffsetDateTime.now&#40;&#41;.minusDays&#40;3&#41;&#41;;\n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions&#40;&#41;\n     .setBlockSizeLong&#40;blockSize&#41;\n     .setMaxConcurrency&#40;maxConcurrency&#41;;\n \n client.uploadWithResponse&#40;new BlobParallelUploadOptions&#40;data&#41;\n     .setParallelTransferOptions&#40;parallelTransferOptions&#41;.setHeaders&#40;headers&#41;.setMetadata&#40;metadata&#41;\n     .setTags&#40;tags&#41;.setTier&#40;AccessTier.HOT&#41;.setRequestConditions&#40;requestConditions&#41;&#41;\n     .subscribe&#40;response -&gt; System.out.printf&#40;&quot;Uploaded BlockBlob MD5 is %s%n&quot;,\n         Base64.getEncoder&#40;&#41;.encodeToString&#40;response.getValue&#40;&#41;.getContentMd5&#40;&#41;&#41;&#41;&#41;;\n </pre>\n\n <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected\n to produce the same values across subscriptions."
  overridden: com.azure.storage.blob.BlobAsyncClient.uploadWithResponse(com.azure.storage.blob.options.BlobParallelUploadOptions)
  parameters:
  - description: <xref uid="BlobParallelUploadOptions" data-throw-if-not-resolved="false">BlobParallelUploadOptions</xref>
    name: options
    type: <xref href="com.azure.storage.blob.options.BlobParallelUploadOptions?alt=com.azure.storage.blob.options.BlobParallelUploadOptions&text=BlobParallelUploadOptions" data-throw-if-not-resolved="False" />
  syntax: public Mono<Response<BlockBlobItem>> uploadWithResponse(BlobParallelUploadOptions options)
  returns:
    description: A reactive response containing the information of the uploaded block blob.
    type: <xref href="reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono" data-throw-if-not-resolved="False" />&lt;<xref href="com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response" data-throw-if-not-resolved="False" />&lt;<xref href="com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem" data-throw-if-not-resolved="False" />&gt;&gt;
- uid: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.uploadWithResponse(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,com.azure.storage.blob.models.BlobHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.blob.models.AccessTier,com.azure.storage.blob.models.BlobRequestConditions)
  fullName: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)
  name: uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)
  nameWithType: EncryptedBlobAsyncClient.uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)
  summary: "Creates a new block blob, or updates the content of an existing block blob. Updating an existing block blob\n overwrites any existing metadata on the blob. Partial updates are not supported with this method; the content of\n the existing blob is overwritten with the new content. To perform a partial update of a block blob's, use <xref uid=\"BlockBlobAsyncClient#stageBlock(String, Flux, long)\" data-throw-if-not-resolved=\"false\">stageBlock</xref> and\n <xref uid=\"BlockBlobAsyncClient#commitBlockList(List)\" data-throw-if-not-resolved=\"false\">BlockBlobAsyncClient#commitBlockList(List)</xref>, which this method uses internally. For more information,\n see the <a href=\"https://docs.microsoft.com/rest/api/storageservices/put-block\">Azure\n Docs for Put Block</a> and the <a href=\"https://docs.microsoft.com/rest/api/storageservices/put-block-list\">Azure\n Docs for Put Block List</a>.\n <p>\n The data passed need not support multiple subscriptions/be replayable as is required in other upload methods when\n retries are enabled, and the length of the data need not be known in advance. Therefore, this method should\n support uploading any arbitrary data source, including network streams. This behavior is possible because this\n method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while\n this method may offer additional convenience, it will not be as performant as other options, which should be\n preferred when possible.\n <p>\n Typically, the greater the number of buffers used, the greater the possible parallelism when transferring the\n data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The\n trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs\n for a given scenario.\n\n <p><strong>Code Samples</strong></p>\n\n <pre>\n BlobHttpHeaders headers = new BlobHttpHeaders&#40;&#41;\n     .setContentMd5&#40;&quot;data&quot;.getBytes&#40;StandardCharsets.UTF_8&#41;&#41;\n     .setContentLanguage&#40;&quot;en-US&quot;&#41;\n     .setContentType&#40;&quot;binary&quot;&#41;;\n \n Map&lt;String, String&gt; metadata = new HashMap&lt;&gt;&#40;Collections.singletonMap&#40;&quot;metadata&quot;, &quot;value&quot;&#41;&#41;;\n BlobRequestConditions requestConditions = new BlobRequestConditions&#40;&#41;\n     .setLeaseId&#40;leaseId&#41;\n     .setIfUnmodifiedSince&#40;OffsetDateTime.now&#40;&#41;.minusDays&#40;3&#41;&#41;;\n ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions&#40;&#41;\n     .setBlockSizeLong&#40;blockSize&#41;\n     .setMaxConcurrency&#40;maxConcurrency&#41;;\n \n client.uploadWithResponse&#40;data, parallelTransferOptions, headers, metadata, AccessTier.HOT, requestConditions&#41;\n     .subscribe&#40;response -&gt; System.out.printf&#40;&quot;Uploaded BlockBlob MD5 is %s%n&quot;,\n         Base64.getEncoder&#40;&#41;.encodeToString&#40;response.getValue&#40;&#41;.getContentMd5&#40;&#41;&#41;&#41;&#41;;\n </pre>"
  overridden: com.azure.storage.blob.BlobAsyncClient.uploadWithResponse(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,com.azure.storage.blob.models.BlobHttpHeaders,java.util.Map<java.lang.String,java.lang.String>,com.azure.storage.blob.models.AccessTier,com.azure.storage.blob.models.BlobRequestConditions)
  parameters:
  - description: |-
      The data to write to the blob. Unlike other upload methods, this method does not require that the
       <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected
       to produce the same values across subscriptions.
    name: data
    type: <xref href="reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux" data-throw-if-not-resolved="False" />&lt;<xref href="java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer" data-throw-if-not-resolved="False" />&gt;
  - description: <xref uid="ParallelTransferOptions" data-throw-if-not-resolved="false">ParallelTransferOptions</xref> used to configure buffered uploading.
    name: parallelTransferOptions
    type: <xref href="com.azure.storage.blob.models.ParallelTransferOptions?alt=com.azure.storage.blob.models.ParallelTransferOptions&text=ParallelTransferOptions" data-throw-if-not-resolved="False" />
  - description: <xref uid="BlobHttpHeaders" data-throw-if-not-resolved="false">BlobHttpHeaders</xref>
    name: headers
    type: <xref href="com.azure.storage.blob.models.BlobHttpHeaders?alt=com.azure.storage.blob.models.BlobHttpHeaders&text=BlobHttpHeaders" data-throw-if-not-resolved="False" />
  - description: Metadata to associate with the blob.
    name: metadata
    type: <xref href="java.util.Map?alt=java.util.Map&text=Map" data-throw-if-not-resolved="False" />&lt;<xref href="java.lang.String?alt=java.lang.String&text=String" data-throw-if-not-resolved="False" />,<xref href="java.lang.String?alt=java.lang.String&text=String" data-throw-if-not-resolved="False" />&gt;
  - description: <xref uid="AccessTier" data-throw-if-not-resolved="false">AccessTier</xref> for the destination blob.
    name: tier
    type: <xref href="com.azure.storage.blob.models.AccessTier?alt=com.azure.storage.blob.models.AccessTier&text=AccessTier" data-throw-if-not-resolved="False" />
  - description: <xref uid="BlobRequestConditions" data-throw-if-not-resolved="false">BlobRequestConditions</xref>
    name: requestConditions
    type: <xref href="com.azure.storage.blob.models.BlobRequestConditions?alt=com.azure.storage.blob.models.BlobRequestConditions&text=BlobRequestConditions" data-throw-if-not-resolved="False" />
  syntax: public Mono<Response<BlockBlobItem>> uploadWithResponse(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, BlobHttpHeaders headers, Map<String,String> metadata, AccessTier tier, BlobRequestConditions requestConditions)
  returns:
    description: A reactive response containing the information of the uploaded block blob.
    type: <xref href="reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono" data-throw-if-not-resolved="False" />&lt;<xref href="com.azure.core.http.rest.Response?alt=com.azure.core.http.rest.Response&text=Response" data-throw-if-not-resolved="False" />&lt;<xref href="com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem" data-throw-if-not-resolved="False" />&gt;&gt;
type: method
metadata: {}
package: com.azure.storage.blob.specialized.cryptography
artifact: com.azure:azure-storage-blob-cryptography:12.8.0-beta.1
