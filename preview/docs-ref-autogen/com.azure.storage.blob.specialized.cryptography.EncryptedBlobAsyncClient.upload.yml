### YamlMime:JavaMember
uid: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload*
fullName: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload
name: upload
nameWithType: EncryptedBlobAsyncClient.upload
members:
- uid: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions)
  fullName: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)
  name: upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)
  nameWithType: EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)
  summary: |-
    Creates a new block blob. By default this method will not overwrite an existing blob.
     <p>
     Updating an existing block blob overwrites any existing metadata on the blob. Partial updates are not supported
     with this method; the content of the existing blob is overwritten with the new content. To perform a partial
     update of block blob's, use <xref uid="BlockBlobAsyncClient#stageBlock(String, Flux, long)" data-throw-if-not-resolved="false">stageBlock</xref> and <xref uid="BlockBlobAsyncClient#commitBlockList(List)" data-throw-if-not-resolved="false">BlockBlobAsyncClient#commitBlockList(List)</xref> on a regular blob client. For more information, see the
     <a href="https://docs.microsoft.com/rest/api/storageservices/put-block">Azure Docs for Put Block</a> and the
     <a href="https://docs.microsoft.com/rest/api/storageservices/put-block-list">Azure Docs for Put Block List</a>.
     <p>
     The data passed need not support multiple subscriptions/be replayable as is required in other upload methods when
     retries are enabled, and the length of the data need not be known in advance. Therefore, this method should
     support uploading any arbitrary data source, including network streams. This behavior is possible because this
     method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while
     this method may offer additional convenience, it will not be as performant as other options, which should be
     preferred when possible.
     <p>
     Typically, the greater the number of buffers used, the greater the possible parallelism when transferring the
     data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The
     trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs
     for a given scenario.

     <p><strong>Code Samples</strong></p>

     <pre>
     ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions&#40;&#41;
         .setBlockSizeLong&#40;blockSize&#41;
         .setMaxConcurrency&#40;maxConcurrency&#41;;
     client.upload&#40;data, parallelTransferOptions&#41;.subscribe&#40;response -&gt;
         System.out.printf&#40;&quot;Uploaded BlockBlob MD5 is %s%n&quot;,
             Base64.getEncoder&#40;&#41;.encodeToString&#40;response.getContentMd5&#40;&#41;&#41;&#41;&#41;;
     </pre>
  overridden: com.azure.storage.blob.BlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions)
  parameters:
  - description: |-
      The data to write to the blob. Unlike other upload methods, this method does not require that the
       <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected
       to produce the same values across subscriptions.
    name: data
    type: <xref href="reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux" data-throw-if-not-resolved="False" />&lt;<xref href="java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer" data-throw-if-not-resolved="False" />&gt;
  - description: <xref uid="ParallelTransferOptions" data-throw-if-not-resolved="false">ParallelTransferOptions</xref> used to configure buffered uploading.
    name: parallelTransferOptions
    type: <xref href="com.azure.storage.blob.models.ParallelTransferOptions?alt=com.azure.storage.blob.models.ParallelTransferOptions&text=ParallelTransferOptions" data-throw-if-not-resolved="False" />
  syntax: public Mono<BlockBlobItem> upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions)
  returns:
    description: A reactive response containing the information of the uploaded block blob.
    type: <xref href="reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono" data-throw-if-not-resolved="False" />&lt;<xref href="com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem" data-throw-if-not-resolved="False" />&gt;
- uid: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,boolean)
  fullName: com.azure.storage.blob.specialized.cryptography.EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)
  name: upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)
  nameWithType: EncryptedBlobAsyncClient.upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)
  summary: |-
    Creates a new block blob, or updates the content of an existing block blob.
     <p>
     Updating an existing block blob overwrites any existing metadata on the blob. Partial updates are not supported
     with this method; the content of the existing blob is overwritten with the new content. To perform a partial
     update of block blob's, use <xref uid="BlockBlobAsyncClient#stageBlock(String, Flux, long)" data-throw-if-not-resolved="false">stageBlock</xref> and <xref uid="BlockBlobAsyncClient#commitBlockList(List)" data-throw-if-not-resolved="false">BlockBlobAsyncClient#commitBlockList(List)</xref> on a regular blob client. For more information, see the
     <a href="https://docs.microsoft.com/rest/api/storageservices/put-block">Azure Docs for Put Block</a> and the
     <a href="https://docs.microsoft.com/rest/api/storageservices/put-block-list">Azure Docs for Put Block List</a>.
     <p>
     The data passed need not support multiple subscriptions/be replayable as is required in other upload methods when
     retries are enabled, and the length of the data need not be known in advance. Therefore, this method should
     support uploading any arbitrary data source, including network streams. This behavior is possible because this
     method will perform some internal buffering as configured by the blockSize and numBuffers parameters, so while
     this method may offer additional convenience, it will not be as performant as other options, which should be
     preferred when possible.
     <p>
     Typically, the greater the number of buffers used, the greater the possible parallelism when transferring the
     data. Larger buffers means we will have to stage fewer blocks and therefore require fewer IO operations. The
     trade-offs between these values are context-dependent, so some experimentation may be required to optimize inputs
     for a given scenario.

     <p><strong>Code Samples</strong></p>

     <pre>
     ParallelTransferOptions parallelTransferOptions = new ParallelTransferOptions&#40;&#41;
         .setBlockSizeLong&#40;blockSize&#41;
         .setMaxConcurrency&#40;maxConcurrency&#41;;
     boolean overwrite = false; &#47;&#47; Default behavior
     client.upload&#40;data, parallelTransferOptions, overwrite&#41;.subscribe&#40;response -&gt;
         System.out.printf&#40;&quot;Uploaded BlockBlob MD5 is %s%n&quot;,
             Base64.getEncoder&#40;&#41;.encodeToString&#40;response.getContentMd5&#40;&#41;&#41;&#41;&#41;;
     </pre>
  overridden: com.azure.storage.blob.BlobAsyncClient.upload(reactor.core.publisher.Flux<java.nio.ByteBuffer>,com.azure.storage.blob.models.ParallelTransferOptions,boolean)
  parameters:
  - description: |-
      The data to write to the blob. Unlike other upload methods, this method does not require that the
       <code>Flux</code> be replayable. In other words, it does not have to support multiple subscribers and is not expected
       to produce the same values across subscriptions.
    name: data
    type: <xref href="reactor.core.publisher.Flux?alt=reactor.core.publisher.Flux&text=Flux" data-throw-if-not-resolved="False" />&lt;<xref href="java.nio.ByteBuffer?alt=java.nio.ByteBuffer&text=ByteBuffer" data-throw-if-not-resolved="False" />&gt;
  - description: <xref uid="ParallelTransferOptions" data-throw-if-not-resolved="false">ParallelTransferOptions</xref> used to configure buffered uploading.
    name: parallelTransferOptions
    type: <xref href="com.azure.storage.blob.models.ParallelTransferOptions?alt=com.azure.storage.blob.models.ParallelTransferOptions&text=ParallelTransferOptions" data-throw-if-not-resolved="False" />
  - description: Whether or not to overwrite, should data exist on the blob.
    name: overwrite
    type: <xref href="boolean?alt=boolean&text=boolean" data-throw-if-not-resolved="False" />
  syntax: public Mono<BlockBlobItem> upload(Flux<ByteBuffer> data, ParallelTransferOptions parallelTransferOptions, boolean overwrite)
  returns:
    description: A reactive response containing the information of the uploaded block blob.
    type: <xref href="reactor.core.publisher.Mono?alt=reactor.core.publisher.Mono&text=Mono" data-throw-if-not-resolved="False" />&lt;<xref href="com.azure.storage.blob.models.BlockBlobItem?alt=com.azure.storage.blob.models.BlockBlobItem&text=BlockBlobItem" data-throw-if-not-resolved="False" />&gt;
type: method
metadata: {}
package: com.azure.storage.blob.specialized.cryptography
artifact: com.azure:azure-storage-blob-cryptography:12.8.0-beta.1
